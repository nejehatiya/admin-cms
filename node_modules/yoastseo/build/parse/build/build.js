"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = build;
var _parse = require("parse5");
var _adapt = _interopRequireDefault(require("./private/adapt"));
var _tokenize = _interopRequireDefault(require("./private/tokenize"));
var _filterTree = _interopRequireDefault(require("./private/filterTree"));
var _alwaysFilterElements = _interopRequireDefault(require("./private/alwaysFilterElements"));
var _filterBeforeTokenizing = require("./private/filterBeforeTokenizing");
var _parseBlocks = _interopRequireDefault(require("./private/parseBlocks"));
var _filterShortcodesFromTree = _interopRequireDefault(require("../../languageProcessing/helpers/sanitize/filterShortcodesFromTree"));
var _htmlEntities = require("../../helpers/htmlEntities");
function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
// External dependencies.

// Internal dependencies.

/**
 * Parses the HTML string to a tree representation of the HTML document.
 *
 * @param {Paper} paper The paper to build the tree from.
 * @param {LanguageProcessor} languageProcessor The language processor to use.
 * @param {string[]} [shortcodes] An optional array of all active shortcodes.
 *
 * @returns {Node} The tree representation of the HTML string.
 */
function build(paper, languageProcessor, shortcodes) {
  let html = paper.getText();
  // Change HTML entities like "&amp;" to "#amp;" to prevent early conversion to "&" -- which would invalidate token positions.
  html = html.replace(_htmlEntities.htmlEntitiesRegex, "#$1");
  let tree = (0, _adapt.default)((0, _parse.parseFragment)(html, {
    sourceCodeLocationInfo: true
  }));
  if (tree.childNodes && tree.childNodes.length > 0) {
    (0, _parseBlocks.default)(paper, tree);
  }

  /*
   * Filter out some content from the tree so that it can be correctly tokenized. We don't want to tokenize text in
   * between tags such as 'code' and 'script', but we do want to take into account the length of those elements when
   * calculating sentence and token positions.
   */
  tree = (0, _filterBeforeTokenizing.filterBeforeTokenizing)(tree);

  // Add sentences and tokens to the tree's paragraph and heading nodes.
  tree = (0, _tokenize.default)(tree, languageProcessor);

  // Filter out shortcodes from the tree.
  if (shortcodes) {
    (0, _filterShortcodesFromTree.default)(tree, shortcodes);
  }

  /*
   * Filter out elements we don't want to include in the analysis. Only do this after tokenization as we need to
   * have all inline elements in the tree during tokenization to correctly calculate sentence and token positions.
   */
  return (0, _filterTree.default)(tree, _alwaysFilterElements.default);
}
//# sourceMappingURL=build.js.map