{
  "_from": "tokenizer2@^2.0.1",
  "_id": "tokenizer2@2.0.1",
  "_inBundle": false,
  "_integrity": "sha512-WAUyv8sbJuFMq4OgQAcXVYrJj1YALGz2Ah4yMyMxRD5DrMnogbtQV3r2RDZ69/Zxh3yYc/olp8rURZ0t3mLevQ==",
  "_location": "/tokenizer2",
  "_phantomChildren": {},
  "_requested": {
    "type": "range",
    "registry": true,
    "raw": "tokenizer2@^2.0.1",
    "name": "tokenizer2",
    "escapedName": "tokenizer2",
    "rawSpec": "^2.0.1",
    "saveSpec": null,
    "fetchSpec": "^2.0.1"
  },
  "_requiredBy": [
    "/yoastseo"
  ],
  "_resolved": "https://registry.npmjs.org/tokenizer2/-/tokenizer2-2.0.1.tgz",
  "_shasum": "c62846214bd05d6b74e4924156d246e6cc070f3e",
  "_spec": "tokenizer2@^2.0.1",
  "_where": "C:\\xampp-8-2\\htdocs\\admin-cms\\node_modules\\yoastseo",
  "author": {
    "name": "smallhelm"
  },
  "bugs": {
    "url": "https://github.com/smallhelm/tokenizer2/issues"
  },
  "bundleDependencies": false,
  "dependencies": {
    "through2": "^2.0.0"
  },
  "deprecated": false,
  "description": "tokenize any text stream given some basic regex rules to match tokens",
  "devDependencies": {
    "tap-min": "^1.0.0",
    "tape": "^4.0.0"
  },
  "files": [
    "core.js",
    "index.js"
  ],
  "homepage": "https://github.com/smallhelm/tokenizer2#readme",
  "keywords": [
    "tokenizer",
    "through",
    "stream"
  ],
  "license": "MIT",
  "main": "index.js",
  "name": "tokenizer2",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/smallhelm/tokenizer2.git"
  },
  "scripts": {
    "test": "node tests.js | tap-min"
  },
  "version": "2.0.1"
}
